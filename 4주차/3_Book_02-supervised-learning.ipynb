{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2장. 지도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*아래 링크를 통해 이 노트북을 주피터 노트북 뷰어(nbviewer.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.*\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.org/github/rickiepark/intro_ml_with_python_2nd_revised/blob/main/02-supervised-learning.ipynb\"><img src=\"https://jupyter.org/assets/share.png\" width=\"60\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/intro_ml_with_python_2nd_revised/blob/main/02-supervised-learning.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=2>이 노트북은 맷플롯립 그래프에 한글을 쓰기 위해 나눔 폰트를 사용합니다. 컴퓨터에 나눔 폰트가 없다면 설치해 주세요.<br><br><font color='red'>주의: 코랩에서 실행하는 경우 아래 셀을 실행하고 ⌘+M . 또는 Ctrl+M . 을 눌러 런타임을 재시작한 다음 처음부터 다시 실행해 주세요.</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노트북이 코랩에서 실행 중인지 체크합니다.\n",
    "import os\n",
    "import sys\n",
    "if 'google.colab' in sys.modules and not os.path.isdir('mglearn'):\n",
    "    # 사이킷런 최신 버전을 설치합니다.\n",
    "    !pip install -q --upgrade scikit-learn\n",
    "    # mglearn을 다운받고 압축을 풉니다.\n",
    "    !wget -q -O mglearn.tar.gz https://bit.ly/mglearn-tar-gz\n",
    "    !tar -xzf mglearn.tar.gz\n",
    "    !wget -q -O data.tar.gz https://bit.ly/data-tar-gz\n",
    "    !tar -xzf data.tar.gz\n",
    "    # 나눔 폰트를 설치합니다.\n",
    "    !sudo apt-get -qq -y install fonts-nanum\n",
    "    import matplotlib.font_manager as fm\n",
    "    fm._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from preamble import *\n",
    "import matplotlib\n",
    "\n",
    "# 나눔 폰트를 사용합니다.\n",
    "matplotlib.rc('font', family='NanumBarunGothic')\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 코랩에서 넘파이 경고를 나타내지 않기 위해\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 분류와 회귀\n",
    "## 2.2 일반화, 과대적합, 과소적합\n",
    "### 2.2.1 모델 복잡도와 데이터셋 사이즈의 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 지도 학습 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "caption": "Forge dataset",
    "label": "forge_scatter"
   },
   "outputs": [],
   "source": [
    "# 데이터셋을 만듭니다\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "# 산점도를 그립니다\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.legend([\"클래스 0\", \"클래스 1\"], loc=4)\n",
    "plt.xlabel(\"첫 번째 특성\")\n",
    "plt.ylabel(\"두 번째 특성\")\n",
    "print(\"X.shape:\", X.shape)\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "plt.plot(X, y, 'o')\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel(\"특성\")\n",
    "plt.ylabel(\"타깃\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys():\\n\", cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"유방암 데이터의 형태:\", cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"클래스별 샘플 갯수:\\n\",\n",
    "      {n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"특성 이름:\\n\", cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보스턴 주택 데이터셋이 1.0 버전에 deprecated 되었고 1.2 버전에서 삭제됩니다.\n",
    "# 경고 메시지를 피하기 위해 다음 코드를 추가합니다.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(\"데이터의 형태:\", boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 k-최근접 이웃\n",
    "#### k-최근접 이웃 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트 세트 예측:\", clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트 세트 정확도: {:.2f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # fit 메소드는 self 오브젝트를 리턴합니다\n",
    "    # 그래서 객체 생성과 fit 메소드를 한 줄에 쓸 수 있습니다\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill=True, eps=0.5, ax=ax, alpha=.4)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(\"{} 이웃\".format(n_neighbors))\n",
    "    ax.set_xlabel(\"특성 0\")\n",
    "    ax.set_ylabel(\"특성 1\")\n",
    "axes[0].legend(loc=3)\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# 1 에서 10 까지 n_neighbors 를 적용\n",
    "neighbors_settings = range(1, 11)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # 모델 생성\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # 훈련 세트 정확도 저장\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # 일반화 정확도 저장\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"훈련 정확도\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"테스트 정확도\")\n",
    "plt.ylabel(\"정확도\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-최근접 이웃 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "\n",
    "# wave 데이터셋을 훈련 세트와 테스트 세트로 나눕니다\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# 이웃의 수를 3으로 하여 모델의 객체를 만듭니다\n",
    "reg = KNeighborsRegressor(n_neighbors=3)\n",
    "# 훈련 데이터와 타깃을 사용하여 모델을 학습시킵니다\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트 세트 예측:\\n\", reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트 세트 R^2: {:.2f}\".format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsRegressor 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "# -3 과 3 사이에 1,000 개의 데이터 포인트를 만듭니다\n",
    "line = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # 1, 3, 9 이웃을 사용한 예측을 합니다\n",
    "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train, y_train)\n",
    "    ax.plot(line, reg.predict(line))\n",
    "    ax.plot(X_train, y_train, '^', c=mglearn.cm2(0), markersize=8)\n",
    "    ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
    "\n",
    "    ax.set_title(\n",
    "        \"{} 이웃의 훈련 스코어: {:.2f} 테스트 스코어: {:.2f}\".format(\n",
    "            n_neighbors, reg.score(X_train, y_train), reg.score(X_test, y_test)))\n",
    "    ax.set_xlabel(\"특성\")\n",
    "    ax.set_ylabel(\"타깃\")\n",
    "axes[0].legend([\"모델 예측\", \"훈련 데이터/타깃\", \"테스트 데이터/타깃\"], loc=\"best\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장단점과 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3. 선형 모델\n",
    "#### 회귀의 선형 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_regression_wave()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형 회귀(최소제곱법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lr.coef_:\", lr.coef_)\n",
    "print(\"lr.intercept_:\", lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"훈련 세트 점수: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"훈련 세트 점수: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 리지 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(ridge10.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(ridge10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(ridge01.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(ridge01.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
    "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
    "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
    "\n",
    "plt.plot(lr.coef_, 'o', label=\"LinearRegression\")\n",
    "plt.xlabel(\"계수 목록\")\n",
    "plt.ylabel(\"계수 크기\")\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-25, 25)\n",
    "plt.legend()\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_ridge_n_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"사용한 특성의 개수:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iter 기본 값을 증가시키지 않으면 max_iter 값을 늘이라는 경고가 발생합니다\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=50000).fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(lasso001.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(lasso001.score(X_test, y_test)))\n",
    "print(\"사용한 특성의 개수:\", np.sum(lasso001.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso00001 = Lasso(alpha=0.0001, max_iter=50000).fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(lasso00001.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(lasso00001.score(X_test, y_test)))\n",
    "print(\"사용한 특성의 개수:\", np.sum(lasso00001.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lasso.coef_, 's', label=\"Lasso alpha=1\")\n",
    "plt.plot(lasso001.coef_, '^', label=\"Lasso alpha=0.01\")\n",
    "plt.plot(lasso00001.coef_, 'v', label=\"Lasso alpha=0.0001\")\n",
    "\n",
    "plt.plot(ridge01.coef_, 'o', label=\"Ridge alpha=0.1\")\n",
    "plt.legend(ncol=2, loc=(0, 1.05))\n",
    "plt.ylim(-25, 25)\n",
    "plt.xlabel(\"계수 목록\")\n",
    "plt.ylabel(\"계수 크기\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QuantileRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "pred_up = QuantileRegressor(quantile=0.9, alpha=0.01).fit(X_train, y_train).predict(X_test)\n",
    "pred_med = QuantileRegressor(quantile=0.5, alpha=0.01).fit(X_train, y_train).predict(X_test)\n",
    "pred_low = QuantileRegressor(quantile=0.1, alpha=0.01).fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "plt.scatter(X_train, y_train, label='훈련 데이터')\n",
    "plt.scatter(X_test, y_test, label='테스트 데이터')\n",
    "plt.plot(X_test, pred_up, label='백분위:0.9')\n",
    "plt.plot(X_test, pred_med, label='백분위:0.5')\n",
    "plt.plot(X_test, pred_low, label='백분위:0.1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류용 선형 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "for model, ax in zip([LinearSVC(max_iter=5000), LogisticRegression()], axes):\n",
    "    clf = model.fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill=False, eps=0.5,\n",
    "                                    ax=ax, alpha=.7)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(clf.__class__.__name__)\n",
    "    ax.set_xlabel(\"특성 0\")\n",
    "    ax.set_ylabel(\"특성 1\")\n",
    "axes[0].legend()\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_svc_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=5000).fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg100 = LogisticRegression(C=100, max_iter=5000).fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.3f}\".format(logreg100.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg001 = LogisticRegression(C=0.01, max_iter=5000).fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.3f}\".format(logreg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(logreg100.coef_.T, '^', label=\"C=100\")\n",
    "plt.plot(logreg.coef_.T, 'o', label=\"C=1\")\n",
    "plt.plot(logreg001.coef_.T, 'v', label=\"C=0.001\")\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel(\"특성\")\n",
    "plt.ylabel(\"계수 크기\")\n",
    "plt.legend()\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 0.22 버전부터는 `LogisticRegression`의 `solver` 매개변수 기본값이 `lbfgs`로 변경되었습니다. `lbfgs`는 L1 규제를 지원하지 않습니다. 따라서 `solver` 매개변수를 `liblinear`로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, marker in zip([0.001, 1, 100], ['o', '^', 'v']):\n",
    "    lr_l1 = LogisticRegression(solver='liblinear', C=C, penalty=\"l1\", max_iter=1000).fit(X_train, y_train)\n",
    "    print(\"C={:.3f} 인 l1 로지스틱 회귀의 훈련 정확도: {:.2f}\".format(\n",
    "          C, lr_l1.score(X_train, y_train)))\n",
    "    print(\"C={:.3f} 인 l1 로지스틱 회귀의 테스트 정확도: {:.2f}\".format(\n",
    "          C, lr_l1.score(X_test, y_test)))\n",
    "    plt.plot(lr_l1.coef_.T, marker, label=\"C={:.3f}\".format(C))\n",
    "\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.xlabel(\"특성\")\n",
    "plt.ylabel(\"계수 크기\")\n",
    "\n",
    "plt.ylim(-5, 5)\n",
    "plt.legend(loc=3)\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중 클래스 분류용 선형 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(random_state=42)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.legend([\"클래스 0\", \"클래스 1\", \"클래스 2\"])\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = LinearSVC().fit(X, y)\n",
    "print(\"계수 배열의 크기: \", linear_svm.coef_.shape)\n",
    "print(\"절편 배열의 크기: \", linear_svm.intercept_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "line = np.linspace(-15, 15)\n",
    "for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_,\n",
    "                                  mglearn.cm3.colors):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "plt.ylim(-10, 15)\n",
    "plt.xlim(-10, 8)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.legend(['클래스 0', '클래스 1', '클래스 2', '클래스 0 경계', '클래스 1 경계',\n",
    "            '클래스 2 경계'], loc=(1.01, 0.3))\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_2d_classification(linear_svm, X, fill=True, alpha=.7)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "line = np.linspace(-15, 15)\n",
    "for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_,\n",
    "                                  mglearn.cm3.colors):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "plt.legend(['클래스 0', '클래스 1', '클래스 2', '클래스 0 경계', '클래스 1 경계',\n",
    "            '클래스 2 경계'], loc=(1.01, 0.3))\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장단점과 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 줄에서 모델의 객체를 생성과 학습을 한번에 실행합니다\n",
    "logreg = LogisticRegression(max_iter=5000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=5000)\n",
    "y_pred = logreg.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LogisticRegression(max_iter=5000).fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier와 SDGRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_c = SGDClassifier(alpha=0.01, learning_rate='adaptive', \n",
    "                      eta0=0.1, random_state=42, n_jobs=-1)\n",
    "sgd_c.fit(X, y)\n",
    "\n",
    "mglearn.plots.plot_2d_classification(sgd_c, X, fill=True, alpha=.7)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "line = np.linspace(-15, 15)\n",
    "for coef, intercept, color in zip(sgd_c.coef_, sgd_c.intercept_,\n",
    "                                  mglearn.cm3.colors):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "plt.legend(['클래스 0', '클래스 1', '클래스 2', '클래스 0 경계', '클래스 1 경계',\n",
    "            '클래스 2 경계'], loc=(1.01, 0.3))\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "sgd_r = SGDRegressor(learning_rate='adaptive', eta0=0.1, random_state=42)\n",
    "sgd_r.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(sgd_r.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(sgd_r.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 1, 0, 1],\n",
    "              [1, 0, 1, 1],\n",
    "              [0, 0, 0, 1],\n",
    "              [1, 0, 1, 0]])\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    # 각 클래스에 대해 반복\n",
    "    # 특성마다 1 이 나타난 횟수를 센다.\n",
    "    counts[label] = X[y == label].sum(axis=0)\n",
    "print(\"특성 카운트:\\n\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장단점과 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 결정 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_animal_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정 트리 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_tree_progressive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정 트리의 복잡도 제어하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "6e5d7a76-9bba-42f7-b26e-907775d289b2"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정 트리 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"악성\", \"양성\"],\n",
    "                feature_names=cancer.feature_names, impurity=False, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(12,6))\n",
    "plot_tree(tree, class_names=[\"악성\", \"양성\"], feature_names=cancer.feature_names,\n",
    "         impurity=False, filled=True, rounded=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 트리의 특성 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "dc2f68ee-0df0-47ed-b500-7ec99d5a0a5d"
   },
   "outputs": [],
   "source": [
    "print(\"특성 중요도:\\n\", tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = cancer.data.shape[1]\n",
    "    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), cancer.feature_names)\n",
    "    plt.xlabel(\"특성 중요도\")\n",
    "    plt.ylabel(\"특성\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances_cancer(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_tree_not_monotone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ram_prices = pd.read_csv(os.path.join(mglearn.datasets.DATA_PATH, \"ram_price.csv\"))\n",
    "\n",
    "plt.yticks(fontname = \"DejaVu Sans\") # 한글 폰트가 지수에 음수를 표시하지 못하므로 ytick의 폰트를 바꾸어 줍니다.\n",
    "plt.semilogy(ram_prices.date, ram_prices.price)\n",
    "plt.xlabel(\"년\")\n",
    "plt.ylabel(\"가격 ($/Mbyte)\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# 2000년 이전을 훈련 데이터로, 2000년 이후를 테스트 데이터로 만듭니다\n",
    "data_train = ram_prices[ram_prices.date < 2000]\n",
    "data_test = ram_prices[ram_prices.date >= 2000]\n",
    "\n",
    "# 가격 예측을 위해 날짜 특성만을 이용합니다\n",
    "X_train = data_train.date.to_numpy()[:, np.newaxis]\n",
    "# 데이터와 타깃 사이의 관계를 간단하게 만들기 위해 로그 스케일로 바꿉니다\n",
    "y_train = np.log(data_train.price)\n",
    "\n",
    "tree = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "linear_reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# 예측은 전체 기간에 대해서 수행합니다\n",
    "X_all = ram_prices.date.to_numpy()[:, np.newaxis]\n",
    "\n",
    "pred_tree = tree.predict(X_all)\n",
    "pred_lr = linear_reg.predict(X_all)\n",
    "\n",
    "# 예측한 값의 로그 스케일을 되돌립니다\n",
    "price_tree = np.exp(pred_tree)\n",
    "price_lr = np.exp(pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yticks(fontname = \"DejaVu Sans\") # 한글 폰트가 지수에 음수를 표시하지 못하므로 ytick의 폰트를 바꾸어 줍니다.\n",
    "plt.semilogy(data_train.date, data_train.price, label=\"훈련 데이터\")\n",
    "plt.semilogy(data_test.date, data_test.price, label=\"테스트 데이터\")\n",
    "plt.semilogy(ram_prices.date, price_tree, label=\"트리 예측\")\n",
    "plt.semilogy(ram_prices.date, price_lr, label=\"선형회귀 예측\")\n",
    "plt.legend()\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장단점과 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 판다스 데이터 프레임 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree.fit(data_train[['date']], y_train)\n",
    "\n",
    "print('특성 개수:', tree.n_features_in_)\n",
    "print('특성 이름:', tree.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 결정 트리의 앙상블\n",
    "#### 랜덤 포레스트\n",
    "##### 랜덤 포레스트 구축\n",
    "##### 랜덤 포레스트 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "b84dcdfe-994f-4a3d-842e-830153eefc59"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=2)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "76ce4154-b441-475e-97e3-1b507964eb29"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "for i, (ax, tree) in enumerate(zip(axes.ravel(), forest.estimators_)):\n",
    "    ax.set_title(\"트리 {}\".format(i))\n",
    "    mglearn.plots.plot_tree_partition(X, y, tree, ax=ax)\n",
    "    \n",
    "mglearn.plots.plot_2d_separator(forest, X, fill=True, ax=axes[-1, -1], alpha=.4)\n",
    "axes[-1, -1].set_title(\"랜덤 포레스트\")\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances_cancer(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 장단점과 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래디언트 부스팅 회귀 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "plot_feature_importances_cancer(gbrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 장단점과 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.8 커널 서포트 벡터 머신\n",
    "#### 선형 모델과 비선형 특성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(centers=4, random_state=8)\n",
    "y = y % 2\n",
    "\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC(max_iter=5000, tol=1e-3).fit(X, y)\n",
    "\n",
    "mglearn.plots.plot_2d_separator(linear_svm, X)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 특성을 제곱하여 추가합니다\n",
    "X_new = np.hstack([X, X[:, 1:] ** 2])\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D, axes3d\n",
    "figure = plt.figure()\n",
    "# 3차원 그래프\n",
    "if matplotlib.__version__ >= '3.4':\n",
    "    # Axes3D가 자동으로 그림에 추가되는 방식은 matplotlib 3.4 버전에서 deprecated 되었습니다.\n",
    "    # 이와 관련된 경고를 피하려면 auto_add_to_figure=False로 지정하고 figure.add_axes(ax)로 직접 추가하세요.\n",
    "    ax = Axes3D(figure, elev=-152, azim=-26, auto_add_to_figure=False)\n",
    "    figure.add_axes(ax)\n",
    "else:\n",
    "    ax = Axes3D(figure, elev=-152, azim=-26)\n",
    "# y == 0 인 포인트를 먼저 그리고 그 다음 y == 1 인 포인트를 그립니다\n",
    "mask = y == 0\n",
    "ax.scatter(X_new[mask, 0], X_new[mask, 1], X_new[mask, 2], c='b',\n",
    "           cmap=mglearn.cm2, s=60, edgecolor='k')\n",
    "ax.scatter(X_new[~mask, 0], X_new[~mask, 1], X_new[~mask, 2], c='r', marker='^',\n",
    "           cmap=mglearn.cm2, s=60, edgecolor='k')\n",
    "ax.set_xlabel(\"특성0\")\n",
    "ax.set_ylabel(\"특성1\")\n",
    "ax.set_zlabel(\"특성1 ** 2\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_3d = LinearSVC(max_iter=5000).fit(X_new, y)\n",
    "coef, intercept = linear_svm_3d.coef_.ravel(), linear_svm_3d.intercept_\n",
    "\n",
    "# 선형 결정 경계 그리기\n",
    "figure = plt.figure()\n",
    "if matplotlib.__version__ >= '3.4':\n",
    "    # Axes3D가 자동으로 그림에 추가되는 방식은 matplotlib 3.4 버전에서 deprecated됩니다.\n",
    "    # 이와 관련된 경고를 피하려면 auto_add_to_figure=False로 지정하고 figure.add_axes(ax)로 직접 추가하세요.\n",
    "    ax = Axes3D(figure, elev=-152, azim=-26, auto_add_to_figure=False)\n",
    "    figure.add_axes(ax)\n",
    "else:\n",
    "    ax = Axes3D(figure, elev=-152, azim=-26)\n",
    "xx = np.linspace(X_new[:, 0].min() - 2, X_new[:, 0].max() + 2, 50)\n",
    "yy = np.linspace(X_new[:, 1].min() - 2, X_new[:, 1].max() + 2, 50)\n",
    "\n",
    "XX, YY = np.meshgrid(xx, yy)\n",
    "ZZ = (coef[0] * XX + coef[1] * YY + intercept) / -coef[2]\n",
    "ax.plot_surface(XX, YY, ZZ, rstride=8, cstride=8, alpha=0.3)\n",
    "ax.scatter(X_new[mask, 0], X_new[mask, 1], X_new[mask, 2], c='b',\n",
    "           cmap=mglearn.cm2, s=60, edgecolor='k')\n",
    "ax.scatter(X_new[~mask, 0], X_new[~mask, 1], X_new[~mask, 2], c='r', marker='^',\n",
    "           cmap=mglearn.cm2, s=60, edgecolor='k')\n",
    "\n",
    "ax.set_xlabel(\"특성0\")\n",
    "ax.set_ylabel(\"특성1\")\n",
    "ax.set_zlabel(\"특성1 ** 2\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZ = YY ** 2\n",
    "dec = linear_svm_3d.decision_function(np.c_[XX.ravel(), YY.ravel(), ZZ.ravel()])\n",
    "plt.contourf(XX, YY, dec.reshape(XX.shape), levels=[dec.min(), 0, dec.max()],\n",
    "             cmap=mglearn.cm2, alpha=0.5)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 커널 기법\n",
    "#### SVM 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = mglearn.tools.make_handcrafted_dataset()                                                                  \n",
    "svm = SVC(kernel='rbf', C=10, gamma=0.1).fit(X, y)                                                \n",
    "mglearn.plots.plot_2d_separator(svm, X, eps=.5)\n",
    "# 데이터 포인트 그리기\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "# 서포트 벡터\n",
    "sv = svm.support_vectors_\n",
    "# dual_coef_ 의 부호에 의해 서포트 벡터의 클래스 레이블이 결정됩니다\n",
    "sv_labels = svm.dual_coef_.ravel() > 0\n",
    "mglearn.discrete_scatter(sv[:, 0], sv[:, 1], sv_labels, s=15, markeredgewidth=3)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM 매개변수 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "\n",
    "for ax, C in zip(axes, [-1, 0, 3]):\n",
    "    for a, gamma in zip(ax, range(-1, 2)):\n",
    "        mglearn.plots.plot_svm(log_C=C, log_gamma=gamma, ax=a)\n",
    "        \n",
    "axes[0, 0].legend([\"클래스 0\", \"클래스 1\", \"클래스 0 서포트 벡터\", \"클래스 1 서포트 벡터\"],\n",
    "                  ncol=4, loc=(.9, 1.2))\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 0.20 버전에서 `SVC` 클래스의 `gamma` 매개변수 옵션에 `auto`외에 `scale`이 추가되었습니다. `auto`는 `1/n_features`, 즉 특성 개수의 역수입니다. `scale`은 `1/(n_features * X.std())`로 스케일 조정이 되지 않은 특성에서 더 좋은 결과를 만듭니다. 사이킷런 0.22 버전부터는 `gamma` 매개변수의 기본값이 `auto`에서 `scale`로 변경됩니다. 서포트 벡터 머신을 사용하기 전에 특성을 표준화 전처리하면 `scale`과 `auto`는 차이가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "uuid": "19dca39b-9061-4fc6-9aab-f759854ec208"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.2f}\".format(svc.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.2f}\".format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(X_train, manage_ticks=False)\n",
    "plt.yscale(\"symlog\")\n",
    "plt.xlabel(\"특성 목록\")\n",
    "plt.ylabel(\"특성 크기\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM 을 위한 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트에서 특성별 최솟값 계산\n",
    "min_on_training = X_train.min(axis=0)\n",
    "# 훈련 세트에서 특성별 (최댓값 - 최솟값) 범위 계산\n",
    "range_on_training = (X_train - min_on_training).max(axis=0)\n",
    "\n",
    "# 훈련 데이터에 최솟값을 빼고 범위로 나누면\n",
    "# 각 특성에 대해 최솟값은 0 최댓값은 1 임\n",
    "X_train_scaled = (X_train - min_on_training) / range_on_training\n",
    "print(\"특성별 최솟값\\n\", X_train_scaled.min(axis=0))\n",
    "print(\"특성별 최댓값\\n\", X_train_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트에도 같은 작업을 적용하지만\n",
    "# 훈련 세트에서 계산한 최솟값과 범위를 사용합니다(자세한 내용은 3장에 있습니다)\n",
    "X_test_scaled = (X_test - min_on_training) / range_on_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(svc.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(svc.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=20)\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(svc.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(svc.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장단점과 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.9 신경망 (딥러닝)\n",
    "#### 신경망 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_logistic_regression_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_single_hidden_layer_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = np.linspace(-3, 3, 100)\n",
    "plt.plot(line, np.tanh(line), label=\"tanh\")\n",
    "plt.plot(line, np.maximum(line, 0), linestyle='--', label=\"relu\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"relu(x), tanh(x)\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_two_hidden_layer_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', random_state=0).fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[10], \n",
    "                    max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10개의 유닛으로 된 두 개의 은닉층\n",
    "mlp = MLPClassifier(solver='lbfgs', random_state=0,\n",
    "                    hidden_layer_sizes=[10, 10], max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanh 활성화 함수가 적용된 10개의 유닛으로 된 두 개의 은닉층\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='tanh',\n",
    "                    random_state=0, hidden_layer_sizes=[10, 10], max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"특성 0\")\n",
    "plt.ylabel(\"특성 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "for axx, n_hidden_nodes in zip(axes, [10, 100]):\n",
    "    for ax, alpha in zip(axx, [0.0001, 0.01, 0.1, 1]):\n",
    "        mlp = MLPClassifier(solver='lbfgs', random_state=0,\n",
    "                            hidden_layer_sizes=[n_hidden_nodes, n_hidden_nodes],\n",
    "                            alpha=alpha, max_iter=1000)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3, ax=ax)\n",
    "        mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax)\n",
    "        ax.set_title(\"n_hidden=[{}, {}]\\nalpha={:.4f}\".format(\n",
    "                      n_hidden_nodes, n_hidden_nodes, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    mlp = MLPClassifier(solver='lbfgs', random_state=i,\n",
    "                        hidden_layer_sizes=[100, 100])\n",
    "    mlp.fit(X_train, y_train)\n",
    "    mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3, ax=ax)\n",
    "    mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"유방암 데이터의 특성별 최대값:\\n\", cancer.data.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.2f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.2f}\".format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트 각 특성의 평균을 계산합니다\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "# 훈련 세트 각 특성의 표준 편차를 계산합니다\n",
    "std_on_train = X_train.std(axis=0)\n",
    "\n",
    "# 데이터에서 평균을 빼고 표준 편차로 나누면\n",
    "# 평균 0, 표준 편차 1 인 데이터로 변환됩니다.\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train\n",
    "# (훈련 데이터의 평균과 표준 편차를 이용해) 같은 변환을 테스트 세트에도 합니다\n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train\n",
    " \n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, alpha=1, random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.coefs_[0].std(axis=1), mlp.coefs_[0].var(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\n",
    "plt.yticks(range(30), cancer.feature_names)\n",
    "plt.xlabel(\"은닉 유닛\")\n",
    "plt.ylabel(\"입력 특성\")\n",
    "plt.colorbar()\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장단점과 매개변수\n",
    "#### 신경망의 복잡도 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 분류 예측의 불확실성 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(noise=0.25, factor=0.5, random_state=1)\n",
    "\n",
    "# 예제를 위해 클래스의 이름을 \"blue\" 와 \"red\" 로 바꿉니다\n",
    "y_named = np.array([\"blue\", \"red\"])[y]\n",
    "\n",
    "# 여러개의 배열을 한꺼번에 train_test_split 에 넣을 수 있습니다\n",
    "# 훈련 세트와 테스트 세트로 나뉘는 방식은 모두 같습니다.\n",
    "X_train, X_test, y_train_named, y_test_named, y_train, y_test = \\\n",
    "    train_test_split(X, y_named, y, random_state=0)\n",
    "\n",
    "# 그래디언트 부스팅 모델을 만듭니다\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 결정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"결정 함수 결과 형태:\", gbrt.decision_function(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정 함수 결과 중 앞부분 일부를 확인합니다\n",
    "print(\"결정 함수:\\n\", gbrt.decision_function(X_test)[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"임계치와 결정 함수 결과 비교:\\n\",\n",
    "      gbrt.decision_function(X_test) > 0)\n",
    "print(\"예측:\\n\", gbrt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불리언 값을 0과 1로 변환합니다\n",
    "greater_zero = (gbrt.decision_function(X_test) > 0).astype(int)\n",
    "# classes_에 인덱스로 사용합니다\n",
    "pred = gbrt.classes_[greater_zero]\n",
    "# pred 와 gbrt.predict의 결과를 비교합니다\n",
    "print(\"pred 는 예측 결과와 같다:\",\n",
    "      np.all(pred == gbrt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_function = gbrt.decision_function(X_test)\n",
    "print(\"결정 함수 최소값: {:.2f} 최대값: {:.2f}\".format(\n",
    "      np.min(decision_function), np.max(decision_function)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    \n",
    "mglearn.tools.plot_2d_separator(gbrt, X, ax=axes[0], alpha=.4,\n",
    "                                fill=True, cm=mglearn.cm2)\n",
    "scores_image = mglearn.tools.plot_2d_scores(gbrt, X, ax=axes[1],\n",
    "                                            alpha=.4, cm=mglearn.ReBl)\n",
    "\n",
    "for ax in axes:\n",
    "    # 훈련 포인트와 테스트 포인트를 그리기\n",
    "    mglearn.discrete_scatter(X_test[:, 0], X_test[:, 1], y_test,\n",
    "                             markers='^', ax=ax)\n",
    "    mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train,\n",
    "                             markers='o', ax=ax)\n",
    "    ax.set_xlabel(\"특성 0\")\n",
    "    ax.set_ylabel(\"특성 1\")\n",
    "cbar = plt.colorbar(scores_image, ax=axes.tolist())\n",
    "cbar.set_alpha(1)\n",
    "cbar.draw_all()\n",
    "axes[0].legend([\"테스트 클래스 0\", \"테스트 클래스 1\", \"훈련 클래스 0\",\n",
    "                \"훈련 클래스 1\"], ncol=4, loc=(.1, 1.1))\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 예측 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"확률 값의 형태:\", gbrt.predict_proba(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba 결과 중 앞부분 일부를 확인합니다\n",
    "print(\"Predicted probabilities:\\n\",\n",
    "      gbrt.predict_proba(X_test[:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    \n",
    "mglearn.tools.plot_2d_separator(\n",
    "    gbrt, X, ax=axes[0], alpha=.4, fill=True, cm=mglearn.cm2)\n",
    "scores_image = mglearn.tools.plot_2d_scores(\n",
    "    gbrt, X, ax=axes[1], alpha=.5, cm=mglearn.ReBl, function='predict_proba')\n",
    "\n",
    "for ax in axes:\n",
    "    # 훈련 포인트와 테스트 포인트를 그리기\n",
    "    mglearn.discrete_scatter(X_test[:, 0], X_test[:, 1], y_test,\n",
    "                             markers='^', ax=ax)\n",
    "    mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train,\n",
    "                             markers='o', ax=ax)\n",
    "    ax.set_xlabel(\"특성 0\")\n",
    "    ax.set_ylabel(\"특성 1\")\n",
    "# colorbar 를 감추지 않습니다.\n",
    "cbar = plt.colorbar(scores_image, ax=axes.tolist())\n",
    "cbar.set_alpha(1)\n",
    "cbar.draw_all()\n",
    "axes[0].legend([\"테스트 클래스 0\", \"테스트 클래스 1\", \"훈련 클래스 0\",\n",
    "                \"훈련 클래스 1\"], ncol=4, loc=(.1, 1.1))\n",
    "plt.show() # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 다중 분류에서의 불확실성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=42)\n",
    "\n",
    "gbrt = GradientBoostingClassifier(learning_rate=0.01, random_state=0)\n",
    "gbrt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"결정 함수의 결과 형태:\", gbrt.decision_function(X_test).shape)\n",
    "# decision function 결과 중 앞부분 일부를 확인합니다.\n",
    "print(\"결정 함수 결과:\\n\", gbrt.decision_function(X_test)[:6, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"가장 큰 결정 함수의 인덱스:\\n\",\n",
    "      np.argmax(gbrt.decision_function(X_test), axis=1))\n",
    "print(\"예측:\\n\", gbrt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba 결과 중 앞부분 일부를 확인합니다\n",
    "print(\"예측 확률:\\n\", gbrt.predict_proba(X_test)[:6])\n",
    "# 행 방향으로 확률을 더하면 1 이 됩니다\n",
    "print(\"합:\", gbrt.predict_proba(X_test)[:6].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"가장 큰 예측 확률의 인덱스:\\n\",\n",
    "      np.argmax(gbrt.predict_proba(X_test), axis=1))\n",
    "print(\"예측:\\n\", gbrt.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 0.20 버전에서 `LogisticRegression`의 `multi_class` 매개변수 옵션에 `auto`가 추가되었습니다. `auto`로 설정하면 이진 분류이거나 `solver`가 `liblinear`일 경우에는 `ovr`을 선택하고 그 외에는 `multinomial`을 선택합니다. 사이킷런 0.22 버전부터는 `multi_class` 매개변수의 기본값이 `ovr`에서 `auto`로 변경됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# iris 데이터셋의 타깃을 클래스 이름으로 나타내기\n",
    "named_target = iris.target_names[y_train]\n",
    "logreg.fit(X_train, named_target)\n",
    "print(\"훈련 데이터에 있는 클래스 종류:\", logreg.classes_)\n",
    "print(\"예측:\", logreg.predict(X_test)[:10])\n",
    "argmax_dec_func = np.argmax(logreg.decision_function(X_test), axis=1)\n",
    "print(\"가장 큰 결정 함수의 인덱스:\", argmax_dec_func[:10])\n",
    "print(\"인덱스를 classses_에 연결:\",\n",
    "      logreg.classes_[argmax_dec_func][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 요약 및 정리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_metadata": {
   "author": "Andreas C. M\\\"ller",
   "title": "Machine Learning with Python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
